{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "518a443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "706dbae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_count(image_path, model_path, conf_threshold=0.25):\n",
    "    \"\"\"Detect and count vehicles in an image.\"\"\"\n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not read image from {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    # Perform detection\n",
    "    results = model(img, conf=conf_threshold)\n",
    "    \n",
    "    # Initialize counter and processed image\n",
    "    vehicle_counts = {class_name: 0 for class_name in model.names.values()}\n",
    "    \n",
    "    # Process results\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        annotated_frame = r.plot()  # Get annotated frame\n",
    "        \n",
    "        for box in boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            class_name = model.names[cls_id]\n",
    "            vehicle_counts[class_name] += 1\n",
    "    \n",
    "    return vehicle_counts, annotated_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da467e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, model_path, output_path=None, conf_threshold=0.25):\n",
    "    \"\"\"Process a video file for vehicle detection and counting.\"\"\"\n",
    "    # Load model\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video from {video_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Set up video writer if output path is provided\n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    total_vehicles = {class_name: 0 for class_name in model.names.values()}\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    print(f\"Press 'q' to quit early\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        if frame_count % 20 == 0:  # Print status every 20 frames\n",
    "            print(f\"Processing frame {frame_count}\")\n",
    "        \n",
    "        # Process frame\n",
    "        results = model(frame, conf=conf_threshold)\n",
    "        \n",
    "        # Count vehicles\n",
    "        frame_vehicles = {class_name: 0 for class_name in model.names.values()}\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            annotated_frame = r.plot()\n",
    "            \n",
    "            for box in boxes:\n",
    "                cls_id = int(box.cls[0])\n",
    "                class_name = model.names[cls_id]\n",
    "                frame_vehicles[class_name] += 1\n",
    "                total_vehicles[class_name] += 1\n",
    "        \n",
    "        # Display counts on frame\n",
    "        y_pos = 30\n",
    "        cv2.putText(annotated_frame, f\"Frame: {frame_count}\", (10, y_pos), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        y_pos += 30\n",
    "        \n",
    "        for class_name, count in frame_vehicles.items():\n",
    "            if count > 0:\n",
    "                cv2.putText(annotated_frame, f\"{class_name}: {count}\", (10, y_pos), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                y_pos += 30\n",
    "        \n",
    "        # Write frame if output is specified\n",
    "        if output_path:\n",
    "            writer.write(annotated_frame)\n",
    "        \n",
    "        # Display frame\n",
    "        cv2.imshow('Vehicle Detection', annotated_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Processing stopped by user\")\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        writer.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(f\"Video processing completed. {frame_count} frames analyzed.\")\n",
    "    return total_vehicles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c0f9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [01:02<00:00, 105kB/s] \n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca095181",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description=\"Detect and count vehicles using YOLOv8\")\n",
    "    parser.add_argument(\"yolov8n.pt\", required=True, help=\"Path to trained model\")\n",
    "    parser.add_argument(\"\", required=True, help=\"Path to image or video file\")\n",
    "    parser.add_argument(\"--output\", help=\"Path to save output\")\n",
    "    parser.add_argument(\"--conf\", type=float, default=0.25, help=\"Confidence threshold\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if os.path.isfile(args.source):\n",
    "        if args.source.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.jpg', '.png')):\n",
    "            # Process video\n",
    "            counts = process_video(args.source, args.model, args.output, args.conf)\n",
    "            if counts:\n",
    "                print(\"Total vehicle counts:\")\n",
    "                for class_name, count in counts.items():\n",
    "                    if count > 0:\n",
    "                        print(f\"  {class_name}: {count}\")\n",
    "        else:\n",
    "            # Process image\n",
    "            counts, annotated_img = detect_and_count(args.source, args.model, args.conf)\n",
    "            if counts:\n",
    "                print(\"Vehicle counts:\")\n",
    "                for class_name, count in counts.items():\n",
    "                    if count > 0:\n",
    "                        print(f\"  {class_name}: {count}\")\n",
    "                \n",
    "                if args.output:\n",
    "                    cv2.imwrite(args.output, annotated_img)\n",
    "                    print(f\"Saved output to {args.output}\")\n",
    "                \n",
    "                # Display image\n",
    "                cv2.imshow(\"Detection Result\", annotated_img)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(f\"Error: {args.source} is not a valid file\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
