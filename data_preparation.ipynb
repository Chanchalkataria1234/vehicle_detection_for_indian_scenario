{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed1b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "from pathlib import Path\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13fdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"https://universe.roboflow.com/roboflow-gw7yv/vehicles-openimages/dataset/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f98bee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_xml_to_yolo(xml_file, class_map):\n",
    "    \"\"\"Convert XML annotation to YOLO format.\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    img_width = int(root.find('size/width').text)\n",
    "    img_height = int(root.find('size/height').text)\n",
    "    \n",
    "    yolo_annotations = []\n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        if class_name not in class_map:\n",
    "            print(f\"Warning: Class '{class_name}' found in {xml_file} but not in class_map\")\n",
    "            continue\n",
    "            \n",
    "        class_id = class_map[class_name]\n",
    "        bbox = obj.find('bndbox')\n",
    "        xmin = float(bbox.find('xmin').text)\n",
    "        ymin = float(bbox.find('ymin').text)\n",
    "        xmax = float(bbox.find('xmax').text)\n",
    "        ymax = float(bbox.find('ymax').text)\n",
    "        \n",
    "        # Convert to YOLO format (normalized center x, center y, width, height)\n",
    "        x_center = ((xmin + xmax) / 2) / img_width\n",
    "        y_center = ((ymin + ymax) / 2) / img_height\n",
    "        width = (xmax - xmin) / img_width\n",
    "        height = (ymax - ymin) / img_height\n",
    "        \n",
    "        yolo_annotations.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "    \n",
    "    return yolo_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924a6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_classes_from_xml(base_dir):\n",
    "    \"\"\"Discover all class names from XML files in the dataset.\"\"\"\n",
    "    xml_files = []\n",
    "    # Find all XML files recursively\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.xml'):\n",
    "                xml_files.append(os.path.join(root, file))\n",
    "    \n",
    "    discovered_classes = set()\n",
    "    for xml_file in xml_files[:100]:  # Check first 100 files to discover classes\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            for obj in root.findall('object'):\n",
    "                class_name = obj.find('name').text\n",
    "                discovered_classes.add(class_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing {xml_file}: {e}\")\n",
    "    \n",
    "    return list(discovered_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f489f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_annotation_pairs(base_dir):\n",
    "    \"\"\"Find all valid image-annotation pairs regardless of folder structure.\"\"\"\n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for ext in ['.jpg', '.jpeg', '.png']:\n",
    "        image_files.extend(glob.glob(os.path.join(base_dir, '**', f'*{ext}'), recursive=True))\n",
    "    \n",
    "    valid_pairs = []\n",
    "    for img_path in image_files:\n",
    "        base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        # Look for corresponding XML file\n",
    "        xml_files = glob.glob(os.path.join(base_dir, '**', f'{base_name}.xml'), recursive=True)\n",
    "        if xml_files:\n",
    "            valid_pairs.append((img_path, xml_files[0]))\n",
    "    \n",
    "    return valid_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845b00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(base_dir, output_dir, class_list=None, train_ratio=0.8):\n",
    "    \"\"\"Prepare dataset by reorganizing files and converting annotations.\"\"\"\n",
    "    print(f\"Base directory: {base_dir}\")\n",
    "    \n",
    "    # If no class list is provided, discover classes from XML files\n",
    "    if class_list is None or len(class_list) == 0:\n",
    "        print(\"No class list provided, discovering classes from XML files...\")\n",
    "        discovered_classes = discover_classes_from_xml(base_dir)\n",
    "        class_list = discovered_classes\n",
    "        print(f\"Discovered classes: {class_list}\")\n",
    "    else:\n",
    "        print(f\"Using provided class list: {class_list}\")\n",
    "    \n",
    "    # Create class map - case insensitive matching\n",
    "    class_map = {}\n",
    "    for i, class_name in enumerate(class_list):\n",
    "        class_map[class_name] = i\n",
    "        # Also add lowercase version for case-insensitive matching\n",
    "        class_map[class_name.lower()] = i\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(os.path.join(output_dir, 'images', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images', 'val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels', 'train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels', 'val'), exist_ok=True)\n",
    "    \n",
    "    # Find all valid image-annotation pairs\n",
    "    print(\"Finding image-annotation pairs...\")\n",
    "    valid_pairs = find_image_annotation_pairs(base_dir)\n",
    "    print(f\"Found {len(valid_pairs)} valid image-annotation pairs\")\n",
    "    \n",
    "    if len(valid_pairs) == 0:\n",
    "        print(\"Error: No valid image-annotation pairs found!\")\n",
    "        return None\n",
    "    \n",
    "    # Shuffle and split into train/val\n",
    "    random.shuffle(valid_pairs)\n",
    "    split_idx = int(len(valid_pairs) * train_ratio)\n",
    "    train_pairs = valid_pairs[:split_idx]\n",
    "    val_pairs = valid_pairs[split_idx:]\n",
    "    \n",
    "    # Process training pairs\n",
    "    for img_path, xml_path in train_pairs:\n",
    "        # Get base filename\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        \n",
    "        # Copy image\n",
    "        dst_img = os.path.join(output_dir, 'images', 'train', img_filename)\n",
    "        shutil.copy2(img_path, dst_img)\n",
    "        \n",
    "        # Convert and save annotation\n",
    "        try:\n",
    "            yolo_annotations = convert_xml_to_yolo(xml_path, class_map)\n",
    "            if yolo_annotations:\n",
    "                with open(os.path.join(output_dir, 'labels', 'train', f\"{base_name}.txt\"), 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_path}: {e}\")\n",
    "    \n",
    "    # Process validation pairs\n",
    "    for img_path, xml_path in val_pairs:\n",
    "        # Get base filename\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        base_name = os.path.splitext(img_filename)[0]\n",
    "        \n",
    "        # Copy image\n",
    "        dst_img = os.path.join(output_dir, 'images', 'val', img_filename)\n",
    "        shutil.copy2(img_path, dst_img)\n",
    "        \n",
    "        # Convert and save annotation\n",
    "        try:\n",
    "            yolo_annotations = convert_xml_to_yolo(xml_path, class_map)\n",
    "            if yolo_annotations:\n",
    "                with open(os.path.join(output_dir, 'labels', 'val', f\"{base_name}.txt\"), 'w') as f:\n",
    "                    f.write('\\n'.join(yolo_annotations))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_path}: {e}\")\n",
    "    \n",
    "    # Count files\n",
    "    train_img_count = len(os.listdir(os.path.join(output_dir, 'images', 'train')))\n",
    "    val_img_count = len(os.listdir(os.path.join(output_dir, 'images', 'val')))\n",
    "    train_label_count = len(os.listdir(os.path.join(output_dir, 'labels', 'train')))\n",
    "    val_label_count = len(os.listdir(os.path.join(output_dir, 'labels', 'val')))\n",
    "    \n",
    "    print(f\"Dataset statistics:\")\n",
    "    print(f\"  Training: {train_img_count} images, {train_label_count} labels\")\n",
    "    print(f\"  Validation: {val_img_count} images, {val_label_count} labels\")\n",
    "    \n",
    "    # Create YAML file with normalized class names (remove case sensitivity)\n",
    "    normalized_class_list = list(set([cls for cls in class_list]))\n",
    "    \n",
    "    yaml_path = os.path.join(output_dir, 'indian_vehicles.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(f\"# Dataset configuration\\n\")\n",
    "        f.write(f\"path: {os.path.abspath(output_dir)}\\n\")\n",
    "        f.write(f\"train: images/train\\n\")\n",
    "        f.write(f\"val: images/val\\n\\n\")\n",
    "        \n",
    "        f.write(f\"# Classes\\n\")\n",
    "        f.write(f\"names:\\n\")\n",
    "        for i, class_name in enumerate(normalized_class_list):\n",
    "            f.write(f\"  {i}: {class_name}\\n\")\n",
    "    \n",
    "    print(f\"Dataset prepared at {output_dir}\")\n",
    "    print(f\"Configuration saved to {yaml_path}\")\n",
    "    return yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a7f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data path: trafic_data\\train\n",
      "Validation data path: trafic_data\\valid\n",
      "Base directory: trafic_data\\train\n",
      "Using provided class list: ['ambulance', 'army vehicle', 'auto rickshaw', 'bicycle', 'bus', 'car', 'garbagevan', 'human hauler', 'minibus', 'minivan', 'motorbike', 'pickup', 'policecar', 'rickshaw', 'scooter', 'suv', 'taxi', 'three wheelers -CNG-', 'truck', 'van', 'wheelbarrow']\n",
      "Finding image-annotation pairs...\n",
      "Found 0 valid image-annotation pairs\n",
      "Error: No valid image-annotation pairs found!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "   \n",
    "\n",
    "# Simulate command-line arguments\n",
    "import sys\n",
    "sys.argv = ['script_name.py', \n",
    "            r\"trafic_data\\train\", \n",
    "            r\"trafic_data\\valid\"]\n",
    "\n",
    "# Initialize the argument parser\n",
    "parser = argparse.ArgumentParser(description=\"Prepare dataset for YOLOv8 training\")\n",
    "parser.add_argument('train', help=\"Path to original dataset directory\")\n",
    "parser.add_argument('valid', default=\"prepared_dataset\", help=\"Output directory\")\n",
    "parser.add_argument(\"--discover-classes\", action=\"store_true\", help=\"Discover classes from XML files\")\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Print the arguments (for testing purposes)\n",
    "print(\"Training data path:\", args.train)\n",
    "print(\"Validation data path:\", args.valid)\n",
    "classes = []\n",
    "if not args.discover_classes:\n",
    "        classes = [\n",
    "            'ambulance', 'army vehicle', 'auto rickshaw', 'bicycle', 'bus', 'car', 'garbagevan', 'human hauler', 'minibus', 'minivan', 'motorbike', 'pickup', 'policecar', 'rickshaw', 'scooter', 'suv', 'taxi', 'three wheelers -CNG-', 'truck', 'van', 'wheelbarrow']\n",
    "    \n",
    "prepare_dataset(args.train, args.valid, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c4481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
